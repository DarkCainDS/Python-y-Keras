Regularización - Dropout
Overfitting es un problema que ocurre cuando el modelo se aprende de memoria los datos en lugar de aprender acerca del problema que se le presenta

Una red neuronal puede llegar a overfitting porque cada neurona se vuelve más especifica con los datos

Una de las formas más sencillas de reducir el overfitting es usando un modelo más pequeño.

Esto es si tenemos una red demasiado compleja con demasiados parámetros se apegará demasiado a estos datos haciendo overfitting

Y si tenemos una red demasiado sencilla llegaría a underfitting porque no lograría adaptarse al problema siendo tan pequeña

no existe receta de cocina para evitar el underfitting y el overfitting, ni para saber cuántas capas debería tener mi red ni cuantas neuronas debería tener cada capa, aun así, una técnica es empezar con un modelo muy pequeño y una vez cómo se comporta iterar

Regularización
viene de un problema de hacer los datos más regulares

Occam’s Razor “When faced with two equally good hypothesis, always choose the simpler one.”

Reducir la complejidad del modelo, para hacer esto debemos reducir los pesos que arroja nuestra red al entrenar, la regularización se lograr con una fórmula matemática

en la cual la regularización castiga la función de perdida utilizando el valor absoluto del peso o el peso al cuadrado multiplicado por un delta

aquí siendo el valor decisivo lambda $\lambda$ que mientras mayor su valor mayor el efecto de la regularización sobre la función de perdida.

Dropout
Otra técnica para reducir el overfitting es el Dropout

la universidad que planteo esto tuvo la idea haciendo fila en un banco y viendo que cada cierta cantidad de personas de la fila avanzaban los cajeros cambiaban de lugar internamente de forma aleatoria
Esto lo hacen para evitar que una persona que haga fila para ver un cajero reducir la posibilidad de atender alguien que conozca y que estén conspirando o tenga la intención de hacer algún fraude.

entonces pensaron que tal si mis redes neuronales están conspirando entre si con los valores de entrada, entonces qué tal si muevo mis valores de entrada para que la conspiración no sea tan alta

el dropout consiste durante cada una de las épocas apagar ciertas neuronas de forma aleatoria para reducir el exceso de exactitud que ocasiona el overfitting

***********************************
















Cumpliendo el reto
Resultados
Se logra solucionar el problema de overfiting. Los valores del val_loss se bajan en promedio a 0.03 y el val_accuracy obtenido es de 0.82.
Se probado en aumentar la cantidad de capas para mejorar el accuracy, pero el efecto es inverso. Es más, se tienen los mismos resultados del punto anterior con solo una caps
.
res.jpg
Regularización L2
# 1 definición del modelo
regularizedL2_model = models.Sequential()
regularizedL2_model.add(layers.Dense(64, activation='relu', input_shape=(10000,),
                                   kernel_regularizer=regularizers.l2(0.00002)))
regularizedL2_model.add(layers.Dense(64, activation='relu',
                                   kernel_regularizer=regularizers.l2(0.00002)))
regularizedL2_model.add(layers.Dense(46, activation='softmax'))


# 2 Compilación del modelo
regularizedL2_model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['acc'])

# 3 Entrenamiento del modelo
history_regularizedL2_model = regularizedL2_model.fit(partial_x_train,
                                                  partial_y_train,
                                                  epochs=20,
                                                  batch_size=512,
                                                  validation_data=(x_val, y_val))
# 4 Validación
epoch = range(1,len(history_basic_model.history['val_loss'])+1)

plt.plot(epoch,history_regularizedL2_model.history['val_loss'], 'o',label='training')
plt.plot(epoch,history_regularizedL2_model.history['loss'], '--',label='validation')
plt.legend()
plt.title('Loss values - regularized L2 model')
plt.show()
print('='*100)

plt.plot(epoch,history_regularizedL2_model.history['val_loss'], 'o',label='Regularized Model')
plt.plot(epoch,history_basic_model.history['val_loss'], '--',label='Basic Model')
plt.legend()
plt.title('Loss values')
plt.show()
print('='*100)

plt.plot(epoch,history_regularizedL2_model.history['val_acc'], 'o',label='Regularized Model')
plt.plot(epoch,history_basic_model.history['val_acc'], '--',label='Basic Model')
plt.legend()
plt.title('Accuracy values')
plt.show() 
.

Regularización L1
# 1 definición del modelo
regularizedL1_model = models.Sequential()
regularizedL1_model.add(layers.Dense(64, activation='relu', input_shape=(10000,),
                                   kernel_regularizer=regularizers.l1(0.000002)))
regularizedL1_model.add(layers.Dense(64, activation='relu',
                                   kernel_regularizer=regularizers.l1(0.000002)))
regularizedL1_model.add(layers.Dense(46, activation='softmax'))


# 2 Compilación del modelo
regularizedL1_model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['acc'])

# 3 Entrenamiento del modelo
history_regularizedL1_model = regularizedL1_model.fit(partial_x_train,
                                                  partial_y_train,
                                                  epochs=20,
                                                  batch_size=512,
                                                  validation_data=(x_val, y_val))
# 4 Validación
epoch = range(1,len(history_basic_model.history['val_loss'])+1)

plt.plot(epoch,history_regularizedL1_model.history['val_loss'], 'o',label='training')
plt.plot(epoch,history_regularizedL1_model.history['loss'], '--',label='validation')
plt.legend()
plt.title('Loss values - regularized L1 model')
plt.show()
print('='*100)

plt.plot(epoch,history_regularizedL1_model.history['val_loss'], '+',label='Regularized L1 Model')
plt.plot(epoch,history_regularizedL2_model.history['val_loss'], 'o',label='Regularized L2 Model')
plt.plot(epoch,history_basic_model.history['val_loss'], '--',label='Basic Model')
plt.legend()
plt.title('Loss values')
plt.show()
print('='*100)

plt.plot(epoch,history_regularizedL1_model.history['val_acc'], '+',label='Regularized L1 Model')
plt.plot(epoch,history_regularizedL2_model.history['val_acc'], 'o',label='Regularized L2 Model')
plt.plot(epoch,history_basic_model.history['val_acc'], '--',label='Basic Model')
plt.legend()
plt.title('Accuracy values')
plt.show()
.

Regularización con Dropout
# 1 definición del modelo
reg_dropout_model = models.Sequential()
reg_dropout_model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
reg_dropout_model.add(layers.Dropout(0.2))

reg_dropout_model.add(layers.Dense(64, activation='relu'))
reg_dropout_model.add(layers.Dropout(0.2))

reg_dropout_model.add(layers.Dense(64, activation='relu'))
reg_dropout_model.add(layers.Dropout(0.2))

reg_dropout_model.add(layers.Dense(46, activation='softmax'))


# 2 Compilación del modelo
reg_dropout_model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['acc'])

# 3 Entrenamiento del modelo
history_reg_dropout_model = reg_dropout_model.fit(partial_x_train,
                                                  partial_y_train,
                                                  epochs=20,
                                                  batch_size=512,
                                                  validation_data=(x_val, y_val))
# 4 Validación
epoch = range(1,len(history_basic_model.history['val_loss'])+1)

plt.plot(epoch,history_reg_dropout_model.history['val_loss'], 'o',label='training')
plt.plot(epoch,history_reg_dropout_model.history['loss'], '--',label='validation')
plt.legend()
plt.title('Loss values - Dropout Model')
plt.show()
print('='*100)

plt.plot(epoch,history_reg_dropout_model.history['val_loss'], '*',label='Dropout Model')
plt.plot(epoch,history_regularizedL1_model.history['val_loss'], '+',label='Regularized L1 Model')
plt.plot(epoch,history_regularizedL2_model.history['val_loss'], 'o',label='Regularized L2 Model')
plt.plot(epoch,history_basic_model.history['val_loss'], '--',label='Basic Model')
plt.legend()
plt.title('Loss values')
plt.show()
print('='*100)

plt.plot(epoch,history_reg_dropout_model.history['val_acc'], '*',label='Dropout Model')
plt.plot(epoch,history_regularizedL1_model.history['val_acc'], '+',label='Regularized L1 Model')
plt.plot(epoch,history_regularizedL2_model.history['val_acc'], 'o',label='Regularized L2 Model')
plt.plot(epoch,history_basic_model.history['val_acc'], '--',label='Basic Model')
plt.legend()
plt.title('Accuracy values')
plt.show()
Regularización con L1-L2
# 1 definición del modelo
reg_L1L2_model = models.Sequential()
reg_L1L2_model.add(layers.Dense(64, activation='relu', input_shape=(10000,),
                                   kernel_regularizer=regularizers.l1_l2(l1=0.000001, l2=0.00001)))

# reg_L1L2_model.add(layers.Dense(64, activation='relu',
#                                    kernel_regularizer=regularizers.l1_l2(l1=0.000001, l2=0.00001)))

# reg_L1L2_model.add(layers.Dense(64, activation='relu',
#                                    kernel_regularizer=regularizers.l1_l2(l1=0.000001, l2=0.00001)))

reg_L1L2_model.add(layers.Dense(46, activation='softmax'))


# 2 Compilación del modelo
reg_L1L2_model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['acc'])

# 3 Entrenamiento del modelo
history_reg_L1L2_model = reg_L1L2_model.fit(partial_x_train,
                                                  partial_y_train,
                                                  epochs=20,
                                                  batch_size=512,
                                                  validation_data=(x_va